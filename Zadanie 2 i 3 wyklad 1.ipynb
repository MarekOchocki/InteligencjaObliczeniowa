{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNwzYFVKDu/K8mNcX5prpMZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarekOchocki/InteligencjaObliczeniowa/blob/master/Zadanie%202%20i%203%20wyklad%201.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ydjj0T3dp6XV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Marek Ochocki (marcopolo97@vp.pl) i Łukasz Gosek (lukaszjgosek@gmail.com)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iQryd_5EbF9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "01920f88-71d9-47da-ab9f-e643880f2484"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cdCeT4lEdh_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def showOpencvImage(image, isGray=False):\n",
        "    fig = plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(image, cmap = 'gray')\n",
        "    plt.show()\n",
        "\n",
        "def openCVHOG(im):\n",
        "    winSize = (20,20)\n",
        "    blockSize = (10,10)\n",
        "    blockStride = (5,5)\n",
        "    cellSize = (10,10)\n",
        "    nbins = 9\n",
        "    derivAperture = 1\n",
        "    winSigma = -1.\n",
        "    histogramNormType = 0\n",
        "    L2HysThreshold = 0.2\n",
        "    gammaCorrection = 1\n",
        "    nlevels = 64\n",
        "    signedGradients = True\n",
        "\n",
        "    hog = cv2.HOGDescriptor(winSize,blockSize,blockStride,cellSize,nbins,derivAperture,winSigma,histogramNormType,L2HysThreshold,gammaCorrection,nlevels, signedGradients)\n",
        "    descriptor = np.ravel(hog.compute(im))\n",
        "    \n",
        "    return descriptor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16_O1Re7EyZx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "199f176a-254d-49e2-979a-a95e20e1a947"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjiidnQ_E42t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "im_list = [train_images[i] for i in range(0,train_images.shape[0])] + [test_images[i] for i in range(0,test_images.shape[0])]\n",
        "hogdata = [openCVHOG(im) for im in im_list]\n",
        "imData = np.float32(hogdata).reshape(-1,81)\n",
        "\n",
        "trainingSetsCount = 600\n",
        "testingSetsCount = 400\n",
        "lastTestingSetIndex = trainingSetsCount + testingSetsCount"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6eRSxL-Fn_i",
        "colab_type": "text"
      },
      "source": [
        "# **SVC model without deskew preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGG8XDNMFAkl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "2d5e0be3-e34c-4aae-95e5-38f6890c47d9"
      },
      "source": [
        "from sklearn import svm\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "model = svm.SVC(C=15.5,gamma=0.7)\n",
        "model = model.fit(imData[0:trainingSetsCount,:],train_labels[0:trainingSetsCount])\n",
        "\n",
        "pred_labels = model.predict(imData[trainingSetsCount:lastTestingSetIndex,:])\n",
        "mask = pred_labels==train_labels[trainingSetsCount:lastTestingSetIndex]\n",
        "correct = np.count_nonzero(mask)\n",
        "cm = confusion_matrix(train_labels[trainingSetsCount:lastTestingSetIndex], pred_labels)\n",
        "\n",
        "print(correct*100.0/pred_labels.size)\n",
        "print(cm)\n",
        "print(classification_report(train_labels[trainingSetsCount:lastTestingSetIndex], pred_labels))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "91.0\n",
            "[[38  0  0  0  0  0  1  0  0  0]\n",
            " [ 0 37  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 32  0  0  0  0  2  0  1]\n",
            " [ 0  0  1 32  0  0  0  0  0  1]\n",
            " [ 0  0  0  0 38  2  4  0  0  2]\n",
            " [ 0  0  2  1  0 36  0  0  1  1]\n",
            " [ 1  1  0  0  1  0 36  0  1  0]\n",
            " [ 0  0  1  2  1  0  0 51  0  0]\n",
            " [ 0  1  0  0  0  2  0  0 34  1]\n",
            " [ 3  0  0  0  0  0  1  1  0 30]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.97      0.94        39\n",
            "           1       0.95      1.00      0.97        37\n",
            "           2       0.89      0.91      0.90        35\n",
            "           3       0.91      0.94      0.93        34\n",
            "           4       0.95      0.83      0.88        46\n",
            "           5       0.90      0.88      0.89        41\n",
            "           6       0.86      0.90      0.88        40\n",
            "           7       0.94      0.93      0.94        55\n",
            "           8       0.94      0.89      0.92        38\n",
            "           9       0.83      0.86      0.85        35\n",
            "\n",
            "    accuracy                           0.91       400\n",
            "   macro avg       0.91      0.91      0.91       400\n",
            "weighted avg       0.91      0.91      0.91       400\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GB4cVPbmGGcF",
        "colab_type": "text"
      },
      "source": [
        "# **Random Tree Classifier without deskew preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPSQ6B5wGNeN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "fb147039-7ae1-4fb5-bf4e-35ab16ffa881"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rfc =  RandomForestClassifier(max_depth=15, n_estimators=100, max_features=60)\n",
        "rfc = rfc.fit(imData[0:trainingSetsCount,:],train_labels[0:trainingSetsCount])\n",
        "\n",
        "pred_labels = rfc.predict(imData[trainingSetsCount:lastTestingSetIndex,:])\n",
        "\n",
        "mask = pred_labels==train_labels[trainingSetsCount:lastTestingSetIndex]\n",
        "correct = np.count_nonzero(mask)\n",
        "cm = confusion_matrix(train_labels[trainingSetsCount:lastTestingSetIndex], pred_labels)\n",
        "\n",
        "print(correct*100.0/pred_labels.size)\n",
        "print(cm)\n",
        "print(classification_report(train_labels[trainingSetsCount:lastTestingSetIndex], pred_labels))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "83.75\n",
            "[[27  3  1  0  0  0  8  0  0  0]\n",
            " [ 0 36  0  0  0  1  0  0  0  0]\n",
            " [ 0  0 32  0  1  1  0  0  0  1]\n",
            " [ 0  0  1 30  0  3  0  0  0  0]\n",
            " [ 0  0  0  0 43  0  2  0  0  1]\n",
            " [ 0  0  0  2  1 34  0  0  1  3]\n",
            " [ 1  1  0  0  2  2 33  0  0  1]\n",
            " [ 0  0  4  2  1  0  0 48  0  0]\n",
            " [ 3  4  0  0  1  5  0  0 24  1]\n",
            " [ 1  1  2  0  1  1  0  1  0 28]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.69      0.76        39\n",
            "           1       0.80      0.97      0.88        37\n",
            "           2       0.80      0.91      0.85        35\n",
            "           3       0.88      0.88      0.88        34\n",
            "           4       0.86      0.93      0.90        46\n",
            "           5       0.72      0.83      0.77        41\n",
            "           6       0.77      0.82      0.80        40\n",
            "           7       0.98      0.87      0.92        55\n",
            "           8       0.96      0.63      0.76        38\n",
            "           9       0.80      0.80      0.80        35\n",
            "\n",
            "    accuracy                           0.84       400\n",
            "   macro avg       0.84      0.84      0.83       400\n",
            "weighted avg       0.85      0.84      0.84       400\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYEHZjm7HpV0",
        "colab_type": "text"
      },
      "source": [
        "# **Neural Network without deskew preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoAN91NcHuBv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "1476ad4a-c37b-42bc-f2eb-7c4910efe6c1"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "network = models.Sequential()\n",
        "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
        "network.add(layers.Dense(10, activation='softmax'))\n",
        "network.compile(optimizer='rmsprop',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "train_images_for_network = train_images.reshape((60000, 28 * 28))\n",
        "train_images_for_network = train_images_for_network.astype('float32') / 255\n",
        "\n",
        "test_images_for_network = test_images.reshape((10000, 28 * 28))\n",
        "test_images_for_network = test_images_for_network.astype('float32') / 255"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hb3MliQDIRtF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "encoded_train_labels = to_categorical(train_labels)\n",
        "encoded_test_labels = to_categorical(test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwsjrawdIrDG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "31cac635-3d87-4738-d2fb-998d778b012b"
      },
      "source": [
        "network.fit(train_images_for_network, encoded_train_labels, epochs=5, batch_size=128)\n",
        "test_loss, test_acc = network.evaluate(test_images_for_network, encoded_test_labels)\n",
        "print('test_acc:', test_acc)\n",
        "\n",
        "pred_probabilities = network.predict(test_images_for_network)\n",
        "\n",
        "pred_labels = np.argmax(pred_probabilities,-1)\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(test_labels, pred_labels)\n",
        "print(cm)\n",
        "print(classification_report(test_labels, pred_labels))\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/5\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.2628 - acc: 0.9240\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.1084 - acc: 0.9682\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.0727 - acc: 0.9784\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.0536 - acc: 0.9835\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.0403 - acc: 0.9877\n",
            "10000/10000 [==============================] - 0s 42us/step\n",
            "test_acc: 0.9801\n",
            "[[ 970    1    1    0    1    0    4    1    2    0]\n",
            " [   0 1129    2    1    0    1    2    0    0    0]\n",
            " [   4    4 1009    1    1    0    3    6    4    0]\n",
            " [   0    0    4  982    0    7    0   10    3    4]\n",
            " [   2    0    3    0  966    0    3    2    0    6]\n",
            " [   2    0    0    2    1  880    6    0    0    1]\n",
            " [   4    3    2    1    2    3  943    0    0    0]\n",
            " [   1    2    8    1    0    0    0 1012    1    3]\n",
            " [   3    1    6    2    4    4    5    8  938    3]\n",
            " [   1    6    0    4   11    6    0    9    0  972]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99       980\n",
            "           1       0.99      0.99      0.99      1135\n",
            "           2       0.97      0.98      0.98      1032\n",
            "           3       0.99      0.97      0.98      1010\n",
            "           4       0.98      0.98      0.98       982\n",
            "           5       0.98      0.99      0.98       892\n",
            "           6       0.98      0.98      0.98       958\n",
            "           7       0.97      0.98      0.97      1028\n",
            "           8       0.99      0.96      0.98       974\n",
            "           9       0.98      0.96      0.97      1009\n",
            "\n",
            "    accuracy                           0.98     10000\n",
            "   macro avg       0.98      0.98      0.98     10000\n",
            "weighted avg       0.98      0.98      0.98     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHL8qZjYJnFq",
        "colab_type": "text"
      },
      "source": [
        "Dla każdego z klasyfikatorów ich wyniki są porównywalne do tych z deskew preprocessingiem: \\\n",
        "AVC: 91% -> 91% \\\n",
        "RTC: 82.75% -> 83.5% \\\n",
        "ANN: 97.8% -> 98.2%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OehABfjK8dm",
        "colab_type": "text"
      },
      "source": [
        "# **AVC with raw data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-I6-Sjp-LDjl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "70d84209-818e-4b4e-c4fb-1fcf1d70373f"
      },
      "source": [
        "train_images_raw = train_images.reshape((60000, 28 * 28))\n",
        "test_images_raw = test_images.reshape((10000, 28 * 28))\n",
        "\n",
        "model = svm.SVC(C=15.5,gamma=0.7)\n",
        "model = model.fit(train_images_raw[0:trainingSetsCount,:], train_labels[0:trainingSetsCount])\n",
        "\n",
        "pred_labels = model.predict(test_images_raw[0:testingSetsCount,:])\n",
        "mask = pred_labels==test_labels[0:testingSetsCount]\n",
        "correct = np.count_nonzero(mask)\n",
        "cm = confusion_matrix(test_labels[0:testingSetsCount], pred_labels)\n",
        "\n",
        "print(correct*100.0/pred_labels.size)\n",
        "print(cm)\n",
        "print(classification_report(test_labels[0:testingSetsCount], pred_labels))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14.25\n",
            "[[ 0 33  0  0  0  0  0  0  0  0]\n",
            " [ 0 57  0  0  0  0  0  0  0  0]\n",
            " [ 0 44  0  0  0  0  0  0  0  0]\n",
            " [ 0 35  0  0  0  0  0  0  0  0]\n",
            " [ 0 46  0  0  0  0  0  0  0  0]\n",
            " [ 0 42  0  0  0  0  0  0  0  0]\n",
            " [ 0 34  0  0  0  0  0  0  0  0]\n",
            " [ 0 41  0  0  0  0  0  0  0  0]\n",
            " [ 0 27  0  0  0  0  0  0  0  0]\n",
            " [ 0 41  0  0  0  0  0  0  0  0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        33\n",
            "           1       0.14      1.00      0.25        57\n",
            "           2       0.00      0.00      0.00        44\n",
            "           3       0.00      0.00      0.00        35\n",
            "           4       0.00      0.00      0.00        46\n",
            "           5       0.00      0.00      0.00        42\n",
            "           6       0.00      0.00      0.00        34\n",
            "           7       0.00      0.00      0.00        41\n",
            "           8       0.00      0.00      0.00        27\n",
            "           9       0.00      0.00      0.00        41\n",
            "\n",
            "    accuracy                           0.14       400\n",
            "   macro avg       0.01      0.10      0.02       400\n",
            "weighted avg       0.02      0.14      0.04       400\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxNpbYdpODzv",
        "colab_type": "text"
      },
      "source": [
        "# **RFC with raw data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CsIqfNXOHpY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "0c3dfadb-3f99-4a8c-ea22-325fd1d0d9c2"
      },
      "source": [
        "rfc = RandomForestClassifier(max_depth=15, n_estimators=100, max_features=60)\n",
        "rfc = rfc.fit(train_images_raw[0:trainingSetsCount,:], train_labels[0:trainingSetsCount])\n",
        "\n",
        "pred_labels = rfc.predict(test_images_raw[0:testingSetsCount,:])\n",
        "\n",
        "mask = pred_labels==test_labels[0:testingSetsCount]\n",
        "correct = np.count_nonzero(mask)\n",
        "cm = confusion_matrix(test_labels[0:testingSetsCount], pred_labels)\n",
        "\n",
        "print(correct*100.0/pred_labels.size)\n",
        "print(cm)\n",
        "print(classification_report(test_labels[0:testingSetsCount], pred_labels))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "85.0\n",
            "[[33  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 57  0  0  0  0  0  0  0  0]\n",
            " [ 1  2 36  0  0  0  0  4  1  0]\n",
            " [ 1  0  1 27  0  2  1  3  0  0]\n",
            " [ 1  1  1  0 37  0  2  0  0  4]\n",
            " [ 1  1  1  3  2 31  0  1  0  2]\n",
            " [ 1  0  2  0  2  1 27  1  0  0]\n",
            " [ 0  1  0  0  2  0  0 36  0  2]\n",
            " [ 1  0  1  1  1  0  0  0 21  2]\n",
            " [ 0  1  0  1  1  0  0  2  1 35]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      1.00      0.92        33\n",
            "           1       0.90      1.00      0.95        57\n",
            "           2       0.86      0.82      0.84        44\n",
            "           3       0.84      0.77      0.81        35\n",
            "           4       0.82      0.80      0.81        46\n",
            "           5       0.91      0.74      0.82        42\n",
            "           6       0.90      0.79      0.84        34\n",
            "           7       0.77      0.88      0.82        41\n",
            "           8       0.91      0.78      0.84        27\n",
            "           9       0.78      0.85      0.81        41\n",
            "\n",
            "    accuracy                           0.85       400\n",
            "   macro avg       0.85      0.84      0.85       400\n",
            "weighted avg       0.85      0.85      0.85       400\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mluzaoUwPKfz",
        "colab_type": "text"
      },
      "source": [
        "AVC nie poradził sobie z surowymi danymi, natomiast wynik RFC jest podobny do tego z preprocessingiem."
      ]
    }
  ]
}