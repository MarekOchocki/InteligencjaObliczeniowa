{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ydjj0T3dp6XV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Marek Ochocki (marcopolo97@vp.pl) i Łukasz Gosek (lukaszjgosek@gmail.com)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iQryd_5EbF9",
        "colab_type": "code",
        "outputId": "3617a4fd-1d5a-4931-9ef4-1d93a078eedb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cdCeT4lEdh_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def showOpencvImage(image, isGray=False):\n",
        "    fig = plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(image, cmap = 'gray')\n",
        "    plt.show()\n",
        "\n",
        "def openCVHOG(im):\n",
        "    winSize = (20,20)\n",
        "    blockSize = (10,10)\n",
        "    blockStride = (5,5)\n",
        "    cellSize = (10,10)\n",
        "    nbins = 9\n",
        "    derivAperture = 1\n",
        "    winSigma = -1.\n",
        "    histogramNormType = 0\n",
        "    L2HysThreshold = 0.2\n",
        "    gammaCorrection = 1\n",
        "    nlevels = 64\n",
        "    signedGradients = True\n",
        "\n",
        "    hog = cv2.HOGDescriptor(winSize,blockSize,blockStride,cellSize,nbins,derivAperture,winSigma,histogramNormType,L2HysThreshold,gammaCorrection,nlevels, signedGradients)\n",
        "    descriptor = np.ravel(hog.compute(im))\n",
        "    \n",
        "    return descriptor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16_O1Re7EyZx",
        "colab_type": "code",
        "outputId": "90fe5f08-90b1-421c-812a-8e27a44c8f2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjiidnQ_E42t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "im_list = [train_images[i] for i in range(0,train_images.shape[0])] + [test_images[i] for i in range(0,test_images.shape[0])]\n",
        "hogdata = [openCVHOG(im) for im in im_list]\n",
        "imData = np.float32(hogdata).reshape(-1,81)\n",
        "\n",
        "trainingSetsCount = 600\n",
        "testingSetsCount = 400\n",
        "lastTestingSetIndex = trainingSetsCount + testingSetsCount"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6eRSxL-Fn_i",
        "colab_type": "text"
      },
      "source": [
        "# **SVM model without deskew preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GL3huTvbfMc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dad9a034-0a89-4290-d262-8cb6a912c4c2"
      },
      "source": [
        "from sklearn import svm\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "def cross_validate_SVM(k, images, labels, C, gamma):\n",
        "  all_scores = []\n",
        "  num_val_samples = int(len(images)/k)\n",
        "  for i in range(k):\n",
        "    val_data = images[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "    val_targets = labels[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "\n",
        "    partial_train_data = np.concatenate((images[:i * num_val_samples], images[(i + 1) * num_val_samples:]), axis=0)\n",
        "    partial_train_targets = np.concatenate((labels[:i * num_val_samples],labels[(i + 1) * num_val_samples:]), axis=0)\n",
        "    \n",
        "    model = svm.SVC(C=C,gamma=gamma)\n",
        "    model.fit(partial_train_data, partial_train_targets)\n",
        "\n",
        "    \n",
        "    pred_labels = model.predict(val_data)\n",
        "    mask = pred_labels==val_targets\n",
        "    correct = np.count_nonzero(mask)\n",
        "\n",
        "    all_scores.append(correct*100.0/pred_labels.size)\n",
        "  return sum(all_scores) / len(all_scores)\n",
        "\n",
        "cross_validation_results = []\n",
        "\n",
        "for C in np.arange(1.8, 3.0, 0.1):\n",
        "  for gamma in np.arange(0.3, 1.1, 0.1):\n",
        "    cross_validation_results.append([cross_validate_SVM(10, imData[:1000], train_labels[:1000], C, gamma), C, gamma])\n",
        "\n",
        "results = [i[0] for i in cross_validation_results]\n",
        "best_result = cross_validation_results[results.index(max(results))]\n",
        "print(\"Best C and gamma: \" + str(best_result[1]) + \", \" + str(best_result[2]))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best C and gamma: 1.8, 0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGG8XDNMFAkl",
        "colab_type": "code",
        "outputId": "116b3c41-cea3-4626-cde5-e87eedff9bda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "\n",
        "model = svm.SVC(C=1.8,gamma=0.3)\n",
        "model = model.fit(imData[0:trainingSetsCount,:],train_labels[0:trainingSetsCount])\n",
        "\n",
        "pred_labels = model.predict(imData[trainingSetsCount:lastTestingSetIndex,:])\n",
        "mask = pred_labels==train_labels[trainingSetsCount:lastTestingSetIndex]\n",
        "correct = np.count_nonzero(mask)\n",
        "cm = confusion_matrix(train_labels[trainingSetsCount:lastTestingSetIndex], pred_labels)\n",
        "\n",
        "print(correct*100.0/pred_labels.size)\n",
        "print(cm)\n",
        "print(classification_report(train_labels[trainingSetsCount:lastTestingSetIndex], pred_labels))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "90.75\n",
            "[[38  0  1  0  0  0  0  0  0  0]\n",
            " [ 0 37  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 32  0  0  0  0  2  0  1]\n",
            " [ 0  0  1 31  0  1  0  0  0  1]\n",
            " [ 0  0  0  0 39  1  4  0  1  1]\n",
            " [ 0  0  2  1  0 36  0  0  1  1]\n",
            " [ 1  1  0  0  1  0 36  0  1  0]\n",
            " [ 0  0  5  1  1  0  0 48  0  0]\n",
            " [ 0  1  0  0  0  0  0  0 36  1]\n",
            " [ 3  0  0  0  0  0  1  1  0 30]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.97      0.94        39\n",
            "           1       0.95      1.00      0.97        37\n",
            "           2       0.78      0.91      0.84        35\n",
            "           3       0.94      0.91      0.93        34\n",
            "           4       0.95      0.85      0.90        46\n",
            "           5       0.95      0.88      0.91        41\n",
            "           6       0.88      0.90      0.89        40\n",
            "           7       0.94      0.87      0.91        55\n",
            "           8       0.92      0.95      0.94        38\n",
            "           9       0.86      0.86      0.86        35\n",
            "\n",
            "    accuracy                           0.91       400\n",
            "   macro avg       0.91      0.91      0.91       400\n",
            "weighted avg       0.91      0.91      0.91       400\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GB4cVPbmGGcF",
        "colab_type": "text"
      },
      "source": [
        "# **Random Tree Classifier without deskew preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1j6M4LEr5emZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3860144f-ddcb-40a0-e961-d9fdbd76f2ee"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "def cross_validate_RFC(k, images, labels, max_depth, n_estimators, max_features):\n",
        "  all_scores = []\n",
        "  num_val_samples = int(len(images)/k)\n",
        "  for i in range(k):\n",
        "    val_data = images[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "    val_targets = labels[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "\n",
        "    partial_train_data = np.concatenate((images[:i * num_val_samples], images[(i + 1) * num_val_samples:]), axis=0)\n",
        "    partial_train_targets = np.concatenate((labels[:i * num_val_samples],labels[(i + 1) * num_val_samples:]), axis=0)\n",
        "    \n",
        "    model = RandomForestClassifier(max_depth=max_depth, n_estimators=n_estimators, max_features=max_features)\n",
        "    model.fit(partial_train_data, partial_train_targets)\n",
        "\n",
        "    \n",
        "    pred_labels = model.predict(val_data)\n",
        "    mask = pred_labels==val_targets\n",
        "    correct = np.count_nonzero(mask)\n",
        "\n",
        "    all_scores.append(correct*100.0/pred_labels.size)\n",
        "  return sum(all_scores) / len(all_scores)\n",
        "\n",
        "\n",
        "cross_validation_results = []\n",
        "\n",
        "for n_estimators in range(5, 100, 5):\n",
        "  cross_validation_results.append([cross_validate_RFC(10, imData[:1000], train_labels[:1000], 15, n_estimators, 60), n_estimators])\n",
        "\n",
        "results = [i[0] for i in cross_validation_results]\n",
        "best_result = cross_validation_results[results.index(max(results))]\n",
        "print(\"Best n_estimators: \" + str(best_result[1]))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best n_estimators: 85\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPSQ6B5wGNeN",
        "colab_type": "code",
        "outputId": "c891971c-c01b-4a95-e091-6c42512ea6da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "rfc = RandomForestClassifier(max_depth=15, n_estimators=85, max_features=60)\n",
        "rfc = rfc.fit(imData[0:trainingSetsCount,:],train_labels[0:trainingSetsCount])\n",
        "\n",
        "pred_labels = rfc.predict(imData[trainingSetsCount:lastTestingSetIndex,:])\n",
        "\n",
        "mask = pred_labels==train_labels[trainingSetsCount:lastTestingSetIndex]\n",
        "correct = np.count_nonzero(mask)\n",
        "cm = confusion_matrix(train_labels[trainingSetsCount:lastTestingSetIndex], pred_labels)\n",
        "\n",
        "print(correct*100.0/pred_labels.size)\n",
        "print(cm)\n",
        "print(classification_report(train_labels[trainingSetsCount:lastTestingSetIndex], pred_labels))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "83.25\n",
            "[[26  1  2  0  0  0 10  0  0  0]\n",
            " [ 0 36  0  0  0  1  0  0  0  0]\n",
            " [ 0  0 32  0  0  1  0  0  1  1]\n",
            " [ 0  0  2 29  0  3  0  0  0  0]\n",
            " [ 0  0  0  0 43  1  2  0  0  0]\n",
            " [ 0  0  0  2  1 30  1  1  2  4]\n",
            " [ 1  0  0  0  2  2 34  0  1  0]\n",
            " [ 0  0  4  2  1  0  0 48  0  0]\n",
            " [ 1  4  0  0  1  3  0  0 27  2]\n",
            " [ 1  1  2  0  0  1  0  2  0 28]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.67      0.76        39\n",
            "           1       0.86      0.97      0.91        37\n",
            "           2       0.76      0.91      0.83        35\n",
            "           3       0.88      0.85      0.87        34\n",
            "           4       0.90      0.93      0.91        46\n",
            "           5       0.71      0.73      0.72        41\n",
            "           6       0.72      0.85      0.78        40\n",
            "           7       0.94      0.87      0.91        55\n",
            "           8       0.87      0.71      0.78        38\n",
            "           9       0.80      0.80      0.80        35\n",
            "\n",
            "    accuracy                           0.83       400\n",
            "   macro avg       0.83      0.83      0.83       400\n",
            "weighted avg       0.84      0.83      0.83       400\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYEHZjm7HpV0",
        "colab_type": "text"
      },
      "source": [
        "# **Neural Network without deskew preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoAN91NcHuBv",
        "colab_type": "code",
        "outputId": "1476ad4a-c37b-42bc-f2eb-7c4910efe6c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "network = models.Sequential()\n",
        "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
        "network.add(layers.Dense(10, activation='softmax'))\n",
        "network.compile(optimizer='rmsprop',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "train_images_for_network = train_images.reshape((60000, 28 * 28))\n",
        "train_images_for_network = train_images_for_network.astype('float32') / 255\n",
        "\n",
        "test_images_for_network = test_images.reshape((10000, 28 * 28))\n",
        "test_images_for_network = test_images_for_network.astype('float32') / 255"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hb3MliQDIRtF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "encoded_train_labels = to_categorical(train_labels)\n",
        "encoded_test_labels = to_categorical(test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwsjrawdIrDG",
        "colab_type": "code",
        "outputId": "31cac635-3d87-4738-d2fb-998d778b012b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "network.fit(train_images_for_network, encoded_train_labels, epochs=5, batch_size=128)\n",
        "test_loss, test_acc = network.evaluate(test_images_for_network, encoded_test_labels)\n",
        "print('test_acc:', test_acc)\n",
        "\n",
        "pred_probabilities = network.predict(test_images_for_network)\n",
        "\n",
        "pred_labels = np.argmax(pred_probabilities,-1)\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(test_labels, pred_labels)\n",
        "print(cm)\n",
        "print(classification_report(test_labels, pred_labels))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/5\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.2628 - acc: 0.9240\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.1084 - acc: 0.9682\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.0727 - acc: 0.9784\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.0536 - acc: 0.9835\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.0403 - acc: 0.9877\n",
            "10000/10000 [==============================] - 0s 42us/step\n",
            "test_acc: 0.9801\n",
            "[[ 970    1    1    0    1    0    4    1    2    0]\n",
            " [   0 1129    2    1    0    1    2    0    0    0]\n",
            " [   4    4 1009    1    1    0    3    6    4    0]\n",
            " [   0    0    4  982    0    7    0   10    3    4]\n",
            " [   2    0    3    0  966    0    3    2    0    6]\n",
            " [   2    0    0    2    1  880    6    0    0    1]\n",
            " [   4    3    2    1    2    3  943    0    0    0]\n",
            " [   1    2    8    1    0    0    0 1012    1    3]\n",
            " [   3    1    6    2    4    4    5    8  938    3]\n",
            " [   1    6    0    4   11    6    0    9    0  972]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99       980\n",
            "           1       0.99      0.99      0.99      1135\n",
            "           2       0.97      0.98      0.98      1032\n",
            "           3       0.99      0.97      0.98      1010\n",
            "           4       0.98      0.98      0.98       982\n",
            "           5       0.98      0.99      0.98       892\n",
            "           6       0.98      0.98      0.98       958\n",
            "           7       0.97      0.98      0.97      1028\n",
            "           8       0.99      0.96      0.98       974\n",
            "           9       0.98      0.96      0.97      1009\n",
            "\n",
            "    accuracy                           0.98     10000\n",
            "   macro avg       0.98      0.98      0.98     10000\n",
            "weighted avg       0.98      0.98      0.98     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHL8qZjYJnFq",
        "colab_type": "text"
      },
      "source": [
        "Dla każdego z klasyfikatorów ich wyniki są porównywalne do tych z deskew preprocessingiem: \\\n",
        "AVC: 91% -> 91% \\\n",
        "RTC: 82.75% -> 83.5% \\\n",
        "ANN: 97.8% -> 98.2%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OehABfjK8dm",
        "colab_type": "text"
      },
      "source": [
        "# **AVC with raw data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-I6-Sjp-LDjl",
        "colab_type": "code",
        "outputId": "70d84209-818e-4b4e-c4fb-1fcf1d70373f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "source": [
        "train_images_raw = train_images.reshape((60000, 28 * 28))\n",
        "test_images_raw = test_images.reshape((10000, 28 * 28))\n",
        "\n",
        "model = svm.SVC(C=15.5,gamma=0.7)\n",
        "model = model.fit(train_images_raw[0:trainingSetsCount,:], train_labels[0:trainingSetsCount])\n",
        "\n",
        "pred_labels = model.predict(test_images_raw[0:testingSetsCount,:])\n",
        "mask = pred_labels==test_labels[0:testingSetsCount]\n",
        "correct = np.count_nonzero(mask)\n",
        "cm = confusion_matrix(test_labels[0:testingSetsCount], pred_labels)\n",
        "\n",
        "print(correct*100.0/pred_labels.size)\n",
        "print(cm)\n",
        "print(classification_report(test_labels[0:testingSetsCount], pred_labels))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14.25\n",
            "[[ 0 33  0  0  0  0  0  0  0  0]\n",
            " [ 0 57  0  0  0  0  0  0  0  0]\n",
            " [ 0 44  0  0  0  0  0  0  0  0]\n",
            " [ 0 35  0  0  0  0  0  0  0  0]\n",
            " [ 0 46  0  0  0  0  0  0  0  0]\n",
            " [ 0 42  0  0  0  0  0  0  0  0]\n",
            " [ 0 34  0  0  0  0  0  0  0  0]\n",
            " [ 0 41  0  0  0  0  0  0  0  0]\n",
            " [ 0 27  0  0  0  0  0  0  0  0]\n",
            " [ 0 41  0  0  0  0  0  0  0  0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        33\n",
            "           1       0.14      1.00      0.25        57\n",
            "           2       0.00      0.00      0.00        44\n",
            "           3       0.00      0.00      0.00        35\n",
            "           4       0.00      0.00      0.00        46\n",
            "           5       0.00      0.00      0.00        42\n",
            "           6       0.00      0.00      0.00        34\n",
            "           7       0.00      0.00      0.00        41\n",
            "           8       0.00      0.00      0.00        27\n",
            "           9       0.00      0.00      0.00        41\n",
            "\n",
            "    accuracy                           0.14       400\n",
            "   macro avg       0.01      0.10      0.02       400\n",
            "weighted avg       0.02      0.14      0.04       400\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxNpbYdpODzv",
        "colab_type": "text"
      },
      "source": [
        "# **RFC with raw data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CsIqfNXOHpY",
        "colab_type": "code",
        "outputId": "0c3dfadb-3f99-4a8c-ea22-325fd1d0d9c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "rfc = RandomForestClassifier(max_depth=15, n_estimators=100, max_features=60)\n",
        "rfc = rfc.fit(train_images_raw[0:trainingSetsCount,:], train_labels[0:trainingSetsCount])\n",
        "\n",
        "pred_labels = rfc.predict(test_images_raw[0:testingSetsCount,:])\n",
        "\n",
        "mask = pred_labels==test_labels[0:testingSetsCount]\n",
        "correct = np.count_nonzero(mask)\n",
        "cm = confusion_matrix(test_labels[0:testingSetsCount], pred_labels)\n",
        "\n",
        "print(correct*100.0/pred_labels.size)\n",
        "print(cm)\n",
        "print(classification_report(test_labels[0:testingSetsCount], pred_labels))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "85.0\n",
            "[[33  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 57  0  0  0  0  0  0  0  0]\n",
            " [ 1  2 36  0  0  0  0  4  1  0]\n",
            " [ 1  0  1 27  0  2  1  3  0  0]\n",
            " [ 1  1  1  0 37  0  2  0  0  4]\n",
            " [ 1  1  1  3  2 31  0  1  0  2]\n",
            " [ 1  0  2  0  2  1 27  1  0  0]\n",
            " [ 0  1  0  0  2  0  0 36  0  2]\n",
            " [ 1  0  1  1  1  0  0  0 21  2]\n",
            " [ 0  1  0  1  1  0  0  2  1 35]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      1.00      0.92        33\n",
            "           1       0.90      1.00      0.95        57\n",
            "           2       0.86      0.82      0.84        44\n",
            "           3       0.84      0.77      0.81        35\n",
            "           4       0.82      0.80      0.81        46\n",
            "           5       0.91      0.74      0.82        42\n",
            "           6       0.90      0.79      0.84        34\n",
            "           7       0.77      0.88      0.82        41\n",
            "           8       0.91      0.78      0.84        27\n",
            "           9       0.78      0.85      0.81        41\n",
            "\n",
            "    accuracy                           0.85       400\n",
            "   macro avg       0.85      0.84      0.85       400\n",
            "weighted avg       0.85      0.85      0.85       400\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mluzaoUwPKfz",
        "colab_type": "text"
      },
      "source": [
        "AVC nie poradził sobie z surowymi danymi, natomiast wynik RFC jest podobny do tego z preprocessingiem."
      ]
    }
  ]
}