{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ydjj0T3dp6XV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Marek Ochocki (marcopolo97@vp.pl) i ≈Åukasz Gosek (lukaszjgosek@gmail.com)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iQryd_5EbF9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cdCeT4lEdh_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def showOpencvImage(image, isGray=False):\n",
        "    fig = plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(image, cmap = 'gray')\n",
        "    plt.show()\n",
        "\n",
        "def openCVHOG(im):\n",
        "    winSize = (20,20)\n",
        "    blockSize = (10,10)\n",
        "    blockStride = (5,5)\n",
        "    cellSize = (10,10)\n",
        "    nbins = 9\n",
        "    derivAperture = 1\n",
        "    winSigma = -1.\n",
        "    histogramNormType = 0\n",
        "    L2HysThreshold = 0.2\n",
        "    gammaCorrection = 1\n",
        "    nlevels = 64\n",
        "    signedGradients = True\n",
        "\n",
        "    hog = cv2.HOGDescriptor(winSize,blockSize,blockStride,cellSize,nbins,derivAperture,winSigma,histogramNormType,L2HysThreshold,gammaCorrection,nlevels, signedGradients)\n",
        "    descriptor = np.ravel(hog.compute(im))\n",
        "    \n",
        "    return descriptor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16_O1Re7EyZx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjiidnQ_E42t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "im_list = [train_images[i] for i in range(0,train_images.shape[0])] + [test_images[i] for i in range(0,test_images.shape[0])]\n",
        "hogdata = [openCVHOG(im) for im in im_list]\n",
        "imData = np.float32(hogdata).reshape(-1,81)\n",
        "\n",
        "trainingSetsCount = 600\n",
        "testingSetsCount = 400\n",
        "lastTestingSetIndex = trainingSetsCount + testingSetsCount"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6eRSxL-Fn_i",
        "colab_type": "text"
      },
      "source": [
        "# **SVM model without deskew preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGG8XDNMFAkl",
        "colab_type": "code",
        "outputId": "8883b5eb-e0f5-455e-c58f-95f1fb0e6190",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "from sklearn import svm\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "clf = GridSearchCV(svm.SVC(), {'C':[1+i*0.1 for i in range(20)], 'gamma':[i*0.1 for i in range(1, 10)]})\n",
        "clf.fit(imData[0:trainingSetsCount,:],train_labels[0:trainingSetsCount])\n",
        "model = clf.best_estimator_\n",
        "\n",
        "pred_labels = model.predict(imData[trainingSetsCount:lastTestingSetIndex,:])\n",
        "mask = pred_labels==train_labels[trainingSetsCount:lastTestingSetIndex]\n",
        "correct = np.count_nonzero(mask)\n",
        "cm = confusion_matrix(train_labels[trainingSetsCount:lastTestingSetIndex], pred_labels)\n",
        "\n",
        "print(correct*100.0/pred_labels.size)\n",
        "print(cm)\n",
        "print(classification_report(train_labels[trainingSetsCount:lastTestingSetIndex], pred_labels))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "91.25\n",
            "[[39  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 37  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 33  0  0  0  0  1  0  1]\n",
            " [ 0  0  1 31  0  1  0  0  0  1]\n",
            " [ 1  0  0  0 40  0  3  0  1  1]\n",
            " [ 0  0  2  1  0 36  0  0  1  1]\n",
            " [ 1  1  0  0  1  0 36  0  1  0]\n",
            " [ 0  0  5  2  1  0  0 47  0  0]\n",
            " [ 0  1  0  0  0  0  0  0 36  1]\n",
            " [ 3  0  0  0  0  0  1  1  0 30]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      1.00      0.94        39\n",
            "           1       0.95      1.00      0.97        37\n",
            "           2       0.80      0.94      0.87        35\n",
            "           3       0.91      0.91      0.91        34\n",
            "           4       0.95      0.87      0.91        46\n",
            "           5       0.97      0.88      0.92        41\n",
            "           6       0.90      0.90      0.90        40\n",
            "           7       0.96      0.85      0.90        55\n",
            "           8       0.92      0.95      0.94        38\n",
            "           9       0.86      0.86      0.86        35\n",
            "\n",
            "    accuracy                           0.91       400\n",
            "   macro avg       0.91      0.92      0.91       400\n",
            "weighted avg       0.92      0.91      0.91       400\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GB4cVPbmGGcF",
        "colab_type": "text"
      },
      "source": [
        "# **Random Tree Classifier without deskew preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPSQ6B5wGNeN",
        "colab_type": "code",
        "outputId": "6212b1ef-33a5-436b-85af-750b9a1a9ffe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "clf = GridSearchCV(RandomForestClassifier(), {'max_depth':[i for i in range(5, 20)], 'n_estimators':[i*5 for i in range(1, 20)]})\n",
        "clf.fit(imData[0:trainingSetsCount,:],train_labels[0:trainingSetsCount])\n",
        "rfc = clf.best_estimator_\n",
        "\n",
        "pred_labels = rfc.predict(imData[trainingSetsCount:lastTestingSetIndex,:])\n",
        "\n",
        "mask = pred_labels==train_labels[trainingSetsCount:lastTestingSetIndex]\n",
        "correct = np.count_nonzero(mask)\n",
        "cm = confusion_matrix(train_labels[trainingSetsCount:lastTestingSetIndex], pred_labels)\n",
        "\n",
        "print(correct*100.0/pred_labels.size)\n",
        "print(cm)\n",
        "print(classification_report(train_labels[trainingSetsCount:lastTestingSetIndex], pred_labels))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "89.25\n",
            "[[36  2  1  0  0  0  0  0  0  0]\n",
            " [ 0 37  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 33  0  1  0  0  0  0  1]\n",
            " [ 0  0  1 31  0  2  0  0  0  0]\n",
            " [ 0  0  0  0 42  1  1  0  0  2]\n",
            " [ 0  0  1  1  0 35  1  0  2  1]\n",
            " [ 2  1  0  0  1  1 35  0  0  0]\n",
            " [ 0  0  4  3  1  0  0 47  0  0]\n",
            " [ 0  1  0  0  0  3  0  0 32  2]\n",
            " [ 3  0  0  0  0  1  1  1  0 29]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.92      0.90        39\n",
            "           1       0.90      1.00      0.95        37\n",
            "           2       0.82      0.94      0.88        35\n",
            "           3       0.89      0.91      0.90        34\n",
            "           4       0.93      0.91      0.92        46\n",
            "           5       0.81      0.85      0.83        41\n",
            "           6       0.92      0.88      0.90        40\n",
            "           7       0.98      0.85      0.91        55\n",
            "           8       0.94      0.84      0.89        38\n",
            "           9       0.83      0.83      0.83        35\n",
            "\n",
            "    accuracy                           0.89       400\n",
            "   macro avg       0.89      0.89      0.89       400\n",
            "weighted avg       0.90      0.89      0.89       400\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYEHZjm7HpV0",
        "colab_type": "text"
      },
      "source": [
        "# **Neural Network without deskew preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoAN91NcHuBv",
        "colab_type": "code",
        "outputId": "5e2e6c5b-1435-450d-ee2e-74b9ed325ba9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "network = models.Sequential()\n",
        "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
        "network.add(layers.Dense(10, activation='softmax'))\n",
        "network.compile(optimizer='rmsprop',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "train_images_for_network = train_images.reshape((60000, 28 * 28))\n",
        "train_images_for_network = train_images_for_network.astype('float32') / 255\n",
        "\n",
        "test_images_for_network = test_images.reshape((10000, 28 * 28))\n",
        "test_images_for_network = test_images_for_network.astype('float32') / 255"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hb3MliQDIRtF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "encoded_train_labels = to_categorical(train_labels)\n",
        "encoded_test_labels = to_categorical(test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwsjrawdIrDG",
        "colab_type": "code",
        "outputId": "0cf8fdf6-50c3-4ead-8cbf-a9a075fc7bd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "network.fit(train_images_for_network, encoded_train_labels, epochs=5, batch_size=128)\n",
        "test_loss, test_acc = network.evaluate(test_images_for_network, encoded_test_labels)\n",
        "print('test_acc:', test_acc)\n",
        "\n",
        "pred_probabilities = network.predict(test_images_for_network)\n",
        "\n",
        "pred_labels = np.argmax(pred_probabilities,-1)\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(test_labels, pred_labels)\n",
        "print(cm)\n",
        "print(classification_report(test_labels, pred_labels))\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 4s 69us/step - loss: 0.2597 - accuracy: 0.9248\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.1039 - accuracy: 0.9686\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0678 - accuracy: 0.9793\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.0495 - accuracy: 0.9850\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.0374 - accuracy: 0.9883\n",
            "10000/10000 [==============================] - 0s 46us/step\n",
            "test_acc: 0.9797999858856201\n",
            "[[ 970    0    0    2    1    0    3    1    2    1]\n",
            " [   0 1128    1    1    0    0    2    0    3    0]\n",
            " [   5    1 1001    6    4    0    2    6    7    0]\n",
            " [   0    0    1  992    0    2    0    3    5    7]\n",
            " [   1    0    1    1  973    0    2    0    1    3]\n",
            " [   2    0    0   10    1  865    4    0    7    3]\n",
            " [   2    2    0    1    9    5  937    0    2    0]\n",
            " [   1    6    8    4    4    0    0  992    3   10]\n",
            " [   0    0    2    3    4    3    0    2  955    5]\n",
            " [   1    4    0    4   10    1    0    3    1  985]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       980\n",
            "           1       0.99      0.99      0.99      1135\n",
            "           2       0.99      0.97      0.98      1032\n",
            "           3       0.97      0.98      0.98      1010\n",
            "           4       0.97      0.99      0.98       982\n",
            "           5       0.99      0.97      0.98       892\n",
            "           6       0.99      0.98      0.98       958\n",
            "           7       0.99      0.96      0.97      1028\n",
            "           8       0.97      0.98      0.97       974\n",
            "           9       0.97      0.98      0.97      1009\n",
            "\n",
            "    accuracy                           0.98     10000\n",
            "   macro avg       0.98      0.98      0.98     10000\n",
            "weighted avg       0.98      0.98      0.98     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHL8qZjYJnFq",
        "colab_type": "text"
      },
      "source": [
        "Dla ka≈ºdego z klasyfikator√≥w ich wyniki sƒÖ por√≥wnywalne do tych z deskew preprocessingiem: \\\n",
        "AVC: 91% -> 91% \\\n",
        "RTC: 82.75% -> 87.5% \\\n",
        "ANN: 97.8% -> 98.2%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OehABfjK8dm",
        "colab_type": "text"
      },
      "source": [
        "# **AVC with raw data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-I6-Sjp-LDjl",
        "colab_type": "code",
        "outputId": "9b273867-ec0a-4b9f-eff6-2c44aa17dbe2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "source": [
        "train_images_raw = train_images.reshape((60000, 28 * 28))\n",
        "test_images_raw = test_images.reshape((10000, 28 * 28))\n",
        "\n",
        "clf = GridSearchCV(svm.SVC(), {'C':[1+i*0.1 for i in range(20)], 'gamma':[i*0.1 for i in range(1, 10)]})\n",
        "clf.fit(train_images_raw[0:trainingSetsCount,:], train_labels[0:trainingSetsCount])\n",
        "model = clf.best_estimator_\n",
        "\n",
        "pred_labels = model.predict(test_images_raw[0:testingSetsCount,:])\n",
        "mask = pred_labels==test_labels[0:testingSetsCount]\n",
        "correct = np.count_nonzero(mask)\n",
        "cm = confusion_matrix(test_labels[0:testingSetsCount], pred_labels)\n",
        "\n",
        "print(correct*100.0/pred_labels.size)\n",
        "print(cm)\n",
        "print(classification_report(test_labels[0:testingSetsCount], pred_labels))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14.25\n",
            "[[ 0 33  0  0  0  0  0  0  0  0]\n",
            " [ 0 57  0  0  0  0  0  0  0  0]\n",
            " [ 0 44  0  0  0  0  0  0  0  0]\n",
            " [ 0 35  0  0  0  0  0  0  0  0]\n",
            " [ 0 46  0  0  0  0  0  0  0  0]\n",
            " [ 0 42  0  0  0  0  0  0  0  0]\n",
            " [ 0 34  0  0  0  0  0  0  0  0]\n",
            " [ 0 41  0  0  0  0  0  0  0  0]\n",
            " [ 0 27  0  0  0  0  0  0  0  0]\n",
            " [ 0 41  0  0  0  0  0  0  0  0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        33\n",
            "           1       0.14      1.00      0.25        57\n",
            "           2       0.00      0.00      0.00        44\n",
            "           3       0.00      0.00      0.00        35\n",
            "           4       0.00      0.00      0.00        46\n",
            "           5       0.00      0.00      0.00        42\n",
            "           6       0.00      0.00      0.00        34\n",
            "           7       0.00      0.00      0.00        41\n",
            "           8       0.00      0.00      0.00        27\n",
            "           9       0.00      0.00      0.00        41\n",
            "\n",
            "    accuracy                           0.14       400\n",
            "   macro avg       0.01      0.10      0.02       400\n",
            "weighted avg       0.02      0.14      0.04       400\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxNpbYdpODzv",
        "colab_type": "text"
      },
      "source": [
        "# **RFC with raw data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CsIqfNXOHpY",
        "colab_type": "code",
        "outputId": "ab728497-34d5-49b5-81b1-cbb94f07f12b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "\n",
        "clf = GridSearchCV(RandomForestClassifier(), {'max_depth':[i for i in range(5, 20)], 'n_estimators':[i*5 for i in range(1, 20)]})\n",
        "clf.fit(train_images_raw[0:trainingSetsCount,:], train_labels[0:trainingSetsCount])\n",
        "rfc = clf.best_estimator_\n",
        "\n",
        "pred_labels = rfc.predict(test_images_raw[0:testingSetsCount,:])\n",
        "\n",
        "mask = pred_labels==test_labels[0:testingSetsCount]\n",
        "correct = np.count_nonzero(mask)\n",
        "cm = confusion_matrix(test_labels[0:testingSetsCount], pred_labels)\n",
        "\n",
        "print(correct*100.0/pred_labels.size)\n",
        "print(cm)\n",
        "print(classification_report(test_labels[0:testingSetsCount], pred_labels))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "83.5\n",
            "[[33  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 57  0  0  0  0  0  0  0  0]\n",
            " [ 1  2 34  1  1  0  0  5  0  0]\n",
            " [ 1  0  1 27  0  3  0  2  0  1]\n",
            " [ 0  1  1  0 35  0  1  0  0  8]\n",
            " [ 1  1  0  7  2 28  0  1  1  1]\n",
            " [ 1  0  3  0  1  1 28  0  0  0]\n",
            " [ 0  1  1  1  2  0  0 35  0  1]\n",
            " [ 2  1  1  0  0  0  0  0 21  2]\n",
            " [ 0  1  0  2  0  0  0  1  1 36]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      1.00      0.92        33\n",
            "           1       0.89      1.00      0.94        57\n",
            "           2       0.83      0.77      0.80        44\n",
            "           3       0.71      0.77      0.74        35\n",
            "           4       0.85      0.76      0.80        46\n",
            "           5       0.88      0.67      0.76        42\n",
            "           6       0.97      0.82      0.89        34\n",
            "           7       0.80      0.85      0.82        41\n",
            "           8       0.91      0.78      0.84        27\n",
            "           9       0.73      0.88      0.80        41\n",
            "\n",
            "    accuracy                           0.83       400\n",
            "   macro avg       0.84      0.83      0.83       400\n",
            "weighted avg       0.84      0.83      0.83       400\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mluzaoUwPKfz",
        "colab_type": "text"
      },
      "source": [
        "AVC nie poradzi≈Ç sobie z surowymi danymi, natomiast wynik RFC jest podobny do tego z preprocessingiem."
      ]
    }
  ]
}